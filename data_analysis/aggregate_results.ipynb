{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rebalance instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Overall configurations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Root\n",
    "root_path = os.getcwd().replace(\"\\\\\",\"/\")\n",
    "\n",
    "# Instance settings\n",
    "# instance_settings_path = \"C:/Users/LocalAdmin/IdeaProjects/slevels/src/main/resources/rebalancing/instance_settings_test_rebalancing.json\"\n",
    "instance_settings_path = \"C:/Users/LocalAdmin/IdeaProjects/slevels/src/main/resources/week/allow_hiring.json\"\n",
    "# instance_settings_path = \"C:/Users/LocalAdmin/IdeaProjects/slevels/src/main/resources/rebalancing/no_rebalancing_fast.json\"\n",
    "\n",
    "\n",
    "dict_sl_status = {\"MET\":\"Met\", \"UNMET\":\"Unmet\"}\n",
    "\n",
    "dict_sq_class = {\"A\":\"Business\", \"B\":\"Standard\", \"C\":\"Low-cost\"}\n",
    "category_segmentation = pd.api.types.CategoricalDtype(categories=[\"Business\", \"Standard\", \"Low-cost\"], ordered=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Loading the instance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########### INSTANCE SETTINGS ##################################################\n",
      "{'generate_test_cases': True,\n",
      " 'instance_description': 'Baseline scenario, fixed fleet and no rebalancing '\n",
      "                         '10min',\n",
      " 'instance_name': 'fixedFleetNoRebalFast',\n",
      " 'instances_folder': 'C:/Users/LocalAdmin/IdeaProjects/slevels/instance_output/fixed_fleet_no_rebalancing_fast/',\n",
      " 'labels': {'BA': 'batch_duration',\n",
      "            'CD': 'contract_duration',\n",
      "            'CS': 'customer_segmentation',\n",
      "            'CT': 'clear_target_list_every_round',\n",
      "            'ID': 'instance_description',\n",
      "            'IF': 'initial_fleet',\n",
      "            'IN': 'instance_name',\n",
      "            'MC': 'max_capacity',\n",
      "            'MO': 'allow_many_to_one',\n",
      "            'MR': 'max_requests',\n",
      "            'RE': 'rebalance',\n",
      "            'RT': 'reinsert_targets',\n",
      "            'SD': 'allow_service_deterioration',\n",
      "            'SR': 'service_rate',\n",
      "            'ST': 'simulation_time',\n",
      "            'UR': 'allow_urgent_relocation',\n",
      "            'VH': 'allow_vehicle_hiring'},\n",
      " 'rebalancing_config': {'allow_many_to_one': [True, False],\n",
      "                        'allow_urgent_relocation': [True, False],\n",
      "                        'clear_target_list_every_round': [True, False],\n",
      "                        'reinsert_targets': [True, False]},\n",
      " 'result_folder': 'C:/Users/LocalAdmin/IdeaProjects/slevels/instance_output/fixed_fleet_no_rebalancing_fast/',\n",
      " 'scenario_config': {'allow_service_deterioration': [False],\n",
      "                     'allow_vehicle_creation': [False],\n",
      "                     'allow_vehicle_hiring': [False],\n",
      "                     'batch_duration': [30],\n",
      "                     'contract_duration': [600],\n",
      "                     'customer_segmentation': {'A': {'A': 1, 'B': 0, 'C': 0},\n",
      "                                               'AA': {'A': 0.68,\n",
      "                                                      'B': 0.16,\n",
      "                                                      'C': 0.16},\n",
      "                                               'B': {'A': 0, 'B': 1, 'C': 0},\n",
      "                                               'BB': {'A': 0.16,\n",
      "                                                      'B': 0.68,\n",
      "                                                      'C': 0.16},\n",
      "                                               'C': {'A': 0, 'B': 0, 'C': 1},\n",
      "                                               'CC': {'A': 0.16,\n",
      "                                                      'B': 0.16,\n",
      "                                                      'C': 0.68}},\n",
      "                     'initial_fleet': [1000],\n",
      "                     'max_capacity': [6],\n",
      "                     'max_requests': [1000],\n",
      "                     'rebalance': [False],\n",
      "                     'service_level': {'A': {'pk_delay': 180,\n",
      "                                             'sharing_preference': 0,\n",
      "                                             'trip_delay': 180},\n",
      "                                       'B': {'pk_delay': 300,\n",
      "                                             'sharing_preference': 1,\n",
      "                                             'trip_delay': 600},\n",
      "                                       'C': {'pk_delay': 600,\n",
      "                                             'sharing_preference': 1,\n",
      "                                             'trip_delay': 900}},\n",
      "                     'service_rate': {'S1': {'A': 1, 'B': 0.9, 'C': 0.8}},\n",
      "                     'time_horizon': [600]}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def load_json(path):\n",
    "    \"\"\"Read json file and return dictionary\"\"\"\n",
    "\n",
    "    # Add .json to the end of file if needed\n",
    "    if path.find(\".json\") < 0:\n",
    "        path = path + \".json\"\n",
    "\n",
    "    # Read JSON file\n",
    "    with open(path) as data_file:\n",
    "        data_loaded = json.load(data_file)\n",
    "\n",
    "    return data_loaded\n",
    "\n",
    "instances_dic = load_json(instance_settings_path)\n",
    "\n",
    "# Folder where results will be saved\n",
    "result_folder = instances_dic[\"result_folder\"]\n",
    "request_log_folder = result_folder + \"/request_track\"\n",
    "\n",
    "# Folder where instances are located\n",
    "instances_folder = instances_dic[\"instances_folder\"]\n",
    "\n",
    "# File name aggregated data\n",
    "instance_name = instances_dic[\"instance_name\"]\n",
    "\n",
    "\n",
    "print(\"########### INSTANCE SETTINGS ##################################################\")\n",
    "pprint(instances_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get settings from instance name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E.g.:\n",
    "\n",
    "* Input = `IN-instanceName_BA-30_TH-86400_MR-1000_IF-1000_MC-06_CD-3600-SR-S1_CS-AA_SD_VH_MO_RT_CT_UR`\n",
    "\n",
    "* Output = \n",
    "{allow_many_to_one: True,\n",
    "allow_service_deterioration: True,\n",
    "allow_urgent_relocation: True,\n",
    "allow_vehicle_hiring: True,\n",
    "batch_duration: 30,\n",
    "clear_target_list_every_round: True,\n",
    "contract_duration: 3600,\n",
    "customer_segmentation: AA,\n",
    "initial_fleet: 1000,\n",
    "max_capacity: 06,\n",
    "max_requests: 1000,\n",
    "reinsert_targets: True,\n",
    "time_horizon: 86400}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instance_settings(file_name):\n",
    "    \"\"\" Read file name and return instance settings.\n",
    "    E.g.:\n",
    "     Input = IN-instanceName_BA-30_TH-86400_MR-1000_IF-1000_MC-06_CD-3600-SR-S1_CS-AA_SD_VH_MO_RT_CT_UR\n",
    "     Output = {'allow_many_to_one': True,\n",
    "                'allow_service_deterioration': True,\n",
    "                'allow_urgent_relocation': True,\n",
    "                'allow_vehicle_hiring': True,\n",
    "                'batch_duration': '30',\n",
    "                'clear_target_list_every_round': True,\n",
    "                'contract_duration': '3600',\n",
    "                'customer_segmentation': 'AA',\n",
    "                'initial_fleet': '1000',\n",
    "                'max_capacity': '06',\n",
    "                'max_requests': '1000',\n",
    "                'reinsert_targets': True,\n",
    "                'time_horizon': '86400'}\n",
    "    \"\"\"\n",
    "    label_setting_dic = instances_dic[\"labels\"]\n",
    "    \n",
    "    print(file_name)\n",
    "        \n",
    "    # E.g., ['BA-30', 'TH-86400', 'MR-1000', 'IF-1000', 'MC-06', 'CD-3600-SR-S1', 'CS-AA', 'SD', 'VH', 'MO', 'RT', 'CT', 'UR']\n",
    "    file_instances = file_name.split(\"_\")\n",
    "\n",
    "    instance_settings = dict()\n",
    "\n",
    "    for e in file_instances:\n",
    "        \n",
    "        if e in label_setting_dic.keys():\n",
    "            # E.g., e =  SD\n",
    "            k = label_setting_dic[e]\n",
    "            # E.g., k = allow_service_deterioration\n",
    "            instance_settings[k] = True\n",
    "            \n",
    "        else:\n",
    "            # E.g., lv = [\"BA\", \"30\"]\n",
    "            lv  = e.split('-')\n",
    "            # E.g., e2 = BA\n",
    "            e2 = lv[0]\n",
    "            # E.g., k = batch_duration\n",
    "            k2 = label_setting_dic[e2]\n",
    "            \n",
    "            if len(lv) > 1:\n",
    "                 # E.g., v = '30'\n",
    "                v = lv[1]\n",
    "                instance_settings[k2] = v\n",
    "            else:\n",
    "                # label is not in instance name = False\n",
    "                instance_settings[k] = False\n",
    "\n",
    "    return instance_settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate results (folder round_track)\n",
    "\n",
    "Instance fields in `round_track` folder. Every line is a snapshot of a simulation round of 30 seconds (first column is round `timestamp`):\n",
    "\n",
    "#### Request status per round\n",
    "* `waiting`\n",
    "* `finished`\n",
    "* `denied`\n",
    "* `n_requests`\n",
    "\n",
    "#### Freelance vehicles per round\n",
    "* `hired_vehicles`\n",
    "* `deactivated_vehicles`\n",
    "\n",
    "#### Vehicle status per round\n",
    "* `active_vehicles`\n",
    "* `enroute_count`\n",
    "* `parked_vehicles`\n",
    "* `origin_vehicles`\n",
    "* `rebalancing`\n",
    "* `stopped_rebalancing`\n",
    "* `idle`\n",
    "* `picking_up`\n",
    "* `O1,O2,O3,O4`\n",
    "* `V1,V2,V3,V4`\n",
    "* `distance_traveled_cruising`\n",
    "* `distance_traveled_loaded`\n",
    "* `distance_traveled_rebalancing`\n",
    "* `run_time`\n",
    "\n",
    "#### Vehicle status per round (seats)\n",
    "* `seat_count`\n",
    "* `picking_up_seats`\n",
    "* `rebalancing_seats`\n",
    "* `empty_seats`\n",
    "* `total_capacity`\n",
    "\n",
    "#### Service quality\n",
    "* `pk_delay`\n",
    "* `total_delay`\n",
    "* `A_pk,A_dp,A_count,A_unmet_slevels`\n",
    "* `B_pk,B_dp,B_count,B_unmet_slevels`\n",
    "* `C_pk,C_dp,C_count,C_unmet_slevels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_results_dic(path_experiment, name_experiment):\n",
    "    \n",
    "    # Initial capacity to subtract from total number of seats\n",
    "    capacity_vehicle_initial_fleet = 4\n",
    "    n_initial_fleet = 1000\n",
    "    capacity_initial_fleet = capacity_vehicle_initial_fleet * n_initial_fleet\n",
    "\n",
    "    # Load results\n",
    "    experiment_file = \"{}round_track/{}.csv\".format(path_experiment, name_experiment)\n",
    "    \n",
    "    # print(\"Processing experiment file '{}'\".format(experiment_file))\n",
    "   \n",
    "\n",
    "    df = pd.read_csv(experiment_file, index_col=\"timestamp\",  parse_dates = True)\n",
    "\n",
    "    # Number of requests\n",
    "    total_requests = df[\"n_requests\"].sum()\n",
    "    serviced = df[\"finished\"][-1]\n",
    "    denied = df[\"denied\"][-1]\n",
    "    \n",
    "    # Service quality\n",
    "    sq_classes = [\"A\", \"B\", \"C\"]\n",
    "    sq_settings = [\"pk\", \"dp\", \"count\", \"unmet_slevels\"]\n",
    "    # e.g., ['A_pk', 'A_dp', 'A_count', 'A_unmet_slevels', 'B_pk', 'B_dp', 'B_count', 'B_unmet_slevels', 'C_pk', 'C_dp', 'C_count', 'C_unmet_slevels']\n",
    "    sq_user_labels = [\"{}_{}\".format(sq_class, sq_setting) for sq_class in sq_classes for sq_setting in sq_settings]\n",
    "    sq_user_dic = {l:df[l][-1] for l in sq_user_labels}\n",
    "    \n",
    "    # Distance traveled\n",
    "    distance_cruising = df[\"distance_traveled_cruising\"][-1]\n",
    "    distance_loaded = df[\"distance_traveled_loaded\"][-1]\n",
    "    distance_rebalancing = df[\"distance_traveled_rebalancing\"][-1]\n",
    "    distance_total = distance_cruising + distance_loaded + distance_rebalancing\n",
    "\n",
    "    # Pickup\n",
    "    avg_pk_delay = df[\"pk_delay\"].mean()\n",
    "    avg_ride_delay = df[\"total_delay\"].mean()\n",
    "\n",
    "    # Separate occupancy labels (e.g., O1, O2, O3, etc.)\n",
    "    occupancy_labels = [col for col in list(df) if 'O' in col]\n",
    "    status_labels = [ \"idle\", \"picking_up\"] + occupancy_labels\n",
    "    \n",
    "    \n",
    "    # Get fleet makeup\n",
    "    #fleet_makeup_labels = [col for col in list(df) if 'V' in col]\n",
    "    #fleet_makeup = {mk:df[mk][-1] for mk in fleet_makeup_labels}\n",
    "    #total_seats = {\"seats_\" + k:int(k[1:]) * v for k,v in fleet_makeup.items()}\n",
    "    #total_seats[\"total_seats\"] = sum(total_seats.values())\n",
    "    \n",
    "    # Fleet statistics\n",
    "    avg_seats = df[\"total_capacity\"].mean() - capacity_initial_fleet\n",
    "    median_seats = df[\"total_capacity\"].median() - capacity_initial_fleet\n",
    "    max_seats = df[\"total_capacity\"].max() - capacity_initial_fleet\n",
    "    id_max_seats = df[\"total_capacity\"].idxmax()\n",
    "    max_hired = df[\"hired_vehicles\"].max() - capacity_initial_fleet\n",
    "    median_hired = df[\"hired_vehicles\"].median() - capacity_initial_fleet\n",
    "    mean_hired = df[\"hired_vehicles\"].mean() - capacity_initial_fleet\n",
    "    mean_active = df[\"active_vehicles\"].mean() - capacity_initial_fleet\n",
    "    occupancy = (df[\"seat_count\"]/df['total_capacity']).mean()\n",
    "    \n",
    "    # How many vehicles are active (i.e., servicing customers)?\n",
    "    total_occupied = (df[\"O1\"] + df[\"O2\"] + df[\"O3\"] + df[\"O4\"])\n",
    "    o1 = (df[\"O1\"]/total_occupied).mean()\n",
    "    o2 = (df[\"O2\"]/total_occupied).mean()\n",
    "    o3 = (df[\"O3\"]/total_occupied).mean()\n",
    "    o4 = (df[\"O4\"]/total_occupied).mean()\n",
    "    \n",
    "    # How many vehicle of each capacity hired?\n",
    "    total_hired = (df[\"V1\"] + df[\"V2\"] + df[\"V3\"] + (df[\"V4\"])-1000)\n",
    "    v1 = (df[\"V1\"]/total_hired).mean()\n",
    "    v2 = (df[\"V2\"]/total_hired).mean()\n",
    "    v3 = (df[\"V3\"]/total_hired).mean()\n",
    "    v4 = ((df[\"V4\"]-1000)/total_hired).mean()\n",
    "          \n",
    "    idle_mean = df['idle'].mean()\n",
    "    idle_pickingup = df['picking_up'].mean()\n",
    "    \n",
    "    servicing_seats = (df['seat_count']/df[\"total_capacity\"]).mean()\n",
    "    picking_up_seats = (df['picking_up_seats']/df[\"total_capacity\"]).mean()\n",
    "    rebalancing_seats = (df['rebalancing_seats']/df[\"total_capacity\"]).mean()\n",
    "    parked_seats = (df['empty_seats']/df[\"total_capacity\"]).mean()\n",
    "\n",
    "    # Filter occupancy columns\n",
    "    df_occupancy = df[occupancy_labels]\n",
    "    \n",
    "    # Build fleet status\n",
    "    df_status = pd.DataFrame(df_occupancy)\n",
    "    df_status[\"picking_up\"] = df[\"picking_up\"]\n",
    "    df_status[\"idle\"] = df[\"idle\"]\n",
    "    \n",
    "    # Smooth values\n",
    "    df_occupancy = df_occupancy.rolling(window=24).mean()\n",
    "\n",
    "    # Runtime\n",
    "    total_runtime = df[\"run_time\"].sum()\n",
    "    \n",
    "    avg_runtime = df[\"run_time\"].mean()\n",
    "    \n",
    "    # Dictionary of agreggate data\n",
    "    dic_agreggate_data = {\n",
    "                        \"serviced_seats\": \"{:.2%}\".format(servicing_seats),\n",
    "                        \"picking_up_seats\": \"{:.2%}\".format(picking_up_seats),\n",
    "                        \"rebalancing_seats\": \"{:.2%}\".format(rebalancing_seats),\n",
    "                        \"parked_seats\": \"{:.2%}\".format(parked_seats),\n",
    "                        \"serviced\": \"{:.2%}\".format(serviced/total_requests),\n",
    "                          \"denied\": \"{:.2%}\".format(denied/total_requests),\n",
    "                          'max_hired': max_hired,\n",
    "                          'occupancy':\"{:.2%}\".format(occupancy),\n",
    "                          'o1':\"{:.2%}\".format(o1),\n",
    "                          'o2':\"{:.2%}\".format(o2),\n",
    "                          'o3':\"{:.2%}\".format(o3),\n",
    "                          'o4':\"{:.2%}\".format(o4),\n",
    "                          'v1':\"{:.2%}\".format(v1),\n",
    "                          'v2':\"{:.2%}\".format(v2),\n",
    "                          'v3':\"{:.2%}\".format(v3),\n",
    "                          'v4':\"{:.2%}\".format(v4),\n",
    "                          'mean_hired': \"{:.2f}\".format(mean_hired),\n",
    "                          'median_hired': median_hired,\n",
    "                          'avg_seats': \"{:.2f}\".format(avg_seats),\n",
    "                          'max_seats': max_seats,\n",
    "                          'id_max_seats': id_max_seats,\n",
    "                          'median_seats': median_seats,\n",
    "                          'mean_active': mean_active,\n",
    "                          \"total_requests\": total_requests,\n",
    "                          \"avg_pk_delay\": \"{:.2f}\".format(avg_pk_delay),\n",
    "                          \"avg_ride_delay\": \"{:.2f}\".format(avg_ride_delay),\n",
    "                          \"total_runtime\": \"{:.2f}\".format(total_runtime/1000/60),\n",
    "                          \"avg_runtime\": \"{:.2f}\".format(avg_runtime/1000),\n",
    "                          \"distance_cruising\": \"{:.2%}\".format(distance_cruising/distance_total),\n",
    "                          \"distance_loaded\": \"{:.2%}\".format(distance_loaded/distance_total),\n",
    "                          \"distance_rebalancing\": \"{:.2%}\".format(distance_rebalancing/distance_total),\n",
    "                          \"distance_total\": distance_total//1000}\n",
    "    \n",
    "    # All data\n",
    "    ##dic_ag = {**dic_agreggate_data, **fleet_makeup}\n",
    "    ##dic_ag = {**dic_ag, **total_seats}\n",
    "    #dic_ag = {**dic_ag, **sq_user_dic}\n",
    "    return dic_agreggate_data\n",
    "    #return dic_ag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate results (folder request_track)\n",
    "\n",
    "* `earliest`\n",
    "* `id` = 1, 2, 3, ..., #USERS\n",
    "* `class` = A, B, C\n",
    "* `pk_delay`\n",
    "* `ride_delay`\n",
    "* `pk_time`\n",
    "* `dp_time`\n",
    "* `id_from` = Network id\n",
    "* `id_to` = Network id\n",
    "* `dist` = trip(id_from, id_to) in seconds\n",
    "* `service` = {FLEET, FREELANCE}\n",
    "* `service_level` = {MET, UNMET}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "def get_request_track_dic(path_experiment, name_experiment):\n",
    "    \n",
    "    # Load results\n",
    "    experiment_file = \"{}request_track/{}.csv\".format(path_experiment, name_experiment)\n",
    "    \n",
    "    # print(\"Processing experiment file '{}'\".format(experiment_file))\n",
    "    df = pd.read_csv(experiment_file, index_col=\"earliest\",  parse_dates = True)\n",
    "    \n",
    "    aggfunc = {\"pk_delay\" : ['mean', 'count', 'max']}\n",
    "    \n",
    "    dfp = df.pivot_table(index=\"class\", columns=\"service_level\", aggfunc=aggfunc, values=[\"pk_delay\"])\n",
    "\n",
    "    return dfp"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "def get_request_track_dic(path_experiment, name_experiment):\n",
    "    \n",
    "    # Load results\n",
    "    experiment_file = \"{}request_track/{}.csv\".format(path_experiment, name_experiment)\n",
    "    \n",
    "    # print(\"Processing experiment file '{}'\".format(experiment_file))\n",
    "    df = pd.read_csv(experiment_file, index_col=\"earliest\",  parse_dates = True)\n",
    "    \n",
    "    aggfunc = {\"pk_delay\" : ['mean', 'count', 'max']}\n",
    "    \n",
    "    # Also can be done with pivot table\n",
    "    df_pivot = df.pivot_table(index=\"class\", columns=\"service_level\", aggfunc=aggfunc, values=[\"pk_delay\", \"id_from\"])\n",
    "\n",
    "\n",
    "    service_count = df['service'].value_counts().to_dict()\n",
    "    class_count = df['class'].value_counts().to_dict()\n",
    "    \n",
    "    # How many users had their service levels fulfilled (MET)? How many had their service levels deteriorated, or have been rejected (UNMET)?\n",
    "    service_level = df['service_level'].value_counts().to_dict()  \n",
    "    \n",
    "    # \n",
    "    service_quality_dic = {'A':{'MET': {'Avg.':None, 'Max.':None, 'Count':None}, 'UNMET': {'Avg.':None, 'Max.':None, 'Count':None}},\n",
    "                           'B':{'MET': {'Avg.':None, 'Max.':None, 'Count':None}, 'UNMET': {'Avg.':None, 'Max.':None, 'Count':None}},\n",
    "                           'C':{'MET': {'Avg.':None, 'Max.':None, 'Count':None}, 'UNMET': {'Avg.':None, 'Max.':None, 'Count':None}}}\n",
    " \n",
    "    for sq_class in ['A', 'B', 'C']:\n",
    "        for service_level in [\"MET\", \"UNMET\"]:\n",
    "            filter_sq_sl = (df['class'] == sq_class) & (df['service_level'] == service_level)\n",
    "            service_quality_dic[sq_class][service_level]['Max.'] = df.loc[filter_sq_sl][\"pk_delay\"].max()\n",
    "            service_quality_dic[sq_class][service_level]['Avg.'] = df.loc[filter_sq_sl][\"pk_delay\"].mean()\n",
    "            service_quality_dic[sq_class][service_level]['Count'] = df.loc[filter_sq_sl][\"pk_delay\"].count()\n",
    "    \n",
    "    # How many vehicles (freelance or from initial fleet) serviced each user (considering class and service quality status, that is, MET or UNMET)\n",
    "    fleet_settings_dic = {sq_class:{service_level:df.loc[(df['class']==sq_class) & \n",
    "                                                         (df['service_level']==service_level)][\"service\"].value_counts().to_dict()\n",
    "                                                   \n",
    "                                    for service_level in  [\"MET\", \"UNMET\"]}\n",
    "                          for sq_class in ['A', 'B', 'C']}\n",
    "    \n",
    "    dic_request_track = {\"service_levels\":service_quality_dic,\n",
    "                          \"fleet_settings\":fleet_settings_dic}\n",
    "    \n",
    "    return dic_request_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "def get_request_track_dic(path_experiment, name_experiment):\n",
    "    \n",
    "    # Load results\n",
    "    experiment_file = \"{}request_track/{}.csv\".format(path_experiment, name_experiment)\n",
    "    \n",
    "    # print(\"Processing experiment file '{}'\".format(experiment_file))\n",
    "    df = pd.read_csv(experiment_file, index_col=\"earliest\",  parse_dates = True)\n",
    "    \n",
    "    service_quality_dic = dict()\n",
    " \n",
    "    for service_level in [\"MET\", \"UNMET\"]:\n",
    "        total = df[(df['service_level'] == service_level)][\"pk_delay\"].count()\n",
    "        for sq_class in ['A', 'B', 'C']:\n",
    "            filter_sq_sl = (df['class'] == sq_class) & (df['service_level'] == service_level)\n",
    "            #service_quality_dic[\"{}_{}\".format(service_level, sq_class)] = df.loc[filter_sq_sl][\"pk_delay\"].count()\n",
    "            if service_level == 'MET':\n",
    "                service_quality_dic[\"{}_{}\".format(service_level, sq_class)] = df.loc[filter_sq_sl][\"pk_delay\"].mean()\n",
    "            else:\n",
    "                service_quality_dic[\"{}_{}\".format(service_level, sq_class)] = df.loc[filter_sq_sl][\"pk_delay\"].count()\n",
    "                \n",
    "        service_quality_dic[\"{}_TOTAL\".format(service_level)] = total\n",
    "    \n",
    "    return service_quality_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing single instance"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Processing instance\n",
    "\n",
    "file_name = \"IN-HIRING_BA-30_ST-600_MR-1000_IF-10_MC-4_CS-AA_CD-0_SR-S1_VH_SD_RE_CT_RT_UR\"\n",
    "\n",
    "# Get instance settings according to file name\n",
    "instance_settings = get_instance_settings(file_name)\n",
    "\n",
    "# Filtered instance settings\n",
    "#instance_settings = {key:value for key,value in instance_settings.items() if key in [\"customer_segmentation\",  \"service_rate\", \"contract_duration\"]}\n",
    "#print(\"\\n##### Instance settings ################################################\")\n",
    "#pprint(instance_settings)\n",
    "\n",
    "# Round track data\n",
    "round_track_dic = get_results_dic(instances_folder, file_name)\n",
    "print(\"\\n##### Round track ######################################################\")\n",
    "pprint(round_track_dic)\n",
    "\n",
    "# Request track data\n",
    "#request_track_dic = get_request_track_dic(instances_folder, file_name)\n",
    "#print(\"\\n##### Request track ####################################################\")\n",
    "#pprint(request_track_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_aggregate_request_dic(path_experiment, name_experiment):\n",
    "    \n",
    "    # Load results\n",
    "    experiment_file = \"{}request_track/{}.csv\".format(path_experiment, name_experiment)\n",
    "    \n",
    "   \n",
    "    df = pd.read_csv(experiment_file, index_col = \"earliest\",  parse_dates = True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rebalance and no rebalance aggregate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files in folder: C:/Users/LocalAdmin/IdeaProjects/slevels/instance_output/fixed_fleet_no_rebalancing_fast//request_track\n",
      "IN-fixedFleetNoRebalFast_BA-030_ST-00600_MR-1000_IF-01000_MC-06_CD-600_SR-S1_CS-CC\n"
     ]
    }
   ],
   "source": [
    "# Get all instances in folder\n",
    "instance_file_names = os.listdir(request_log_folder)\n",
    "\n",
    "instance_file_names = [i for i in instance_file_names if instances_dic['instance_name'] in i]\n",
    "\n",
    "# Instance Info (key = instance name)\n",
    "dic_all = dict()\n",
    "print(\"Reading files in folder:\", request_log_folder)\n",
    "\n",
    "count = 1\n",
    "for file_name in instance_file_names:\n",
    "    \n",
    "    \n",
    "        \n",
    "    instance, extension = file_name.split(\".\")\n",
    "    \n",
    "    # Instance settings\n",
    "    instance_settings_dic = get_instance_settings(instance)\n",
    "    if instance_settings_dic['instance_name'] != 'WEEKDENY' or instance_settings_dic['customer_segmentation'] in ['A', 'B', 'C']:\n",
    "        continue\n",
    "        \n",
    "    print(\"  - Processing\", instance)\n",
    "        \n",
    "    count = count + 1\n",
    "    round_track_agg_dic = get_results_dic(instances_folder, instance)\n",
    "    request_track_agg_dic = get_request_track_dic(instances_folder, instance)\n",
    "    \n",
    "    # Get aggregated results\n",
    "    dic_all[instance] = {**instance_settings_dic, **round_track_agg_dic, **request_track_agg_dic}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_hiring = pd.DataFrame.from_dict(dic_all, orient='index')\n",
    "df_no_hiring.to_csv(\"rebal_and_no_rebal.csv\")\n",
    "df_no_hiring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'instance_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\env_slevels\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3077\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3078\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3079\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'instance_name'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-d1ce14eac09e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_no_hiring\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_no_hiring\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'instance_name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'WEEKDENY'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mkey_cs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'customer_segmentation'\u001b[0m \u001b[1;31m# (A, AA, BB, etc.)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mkey_reb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'rebalance'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\env_slevels\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2686\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2687\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2688\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\env_slevels\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2693\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2695\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2697\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\env_slevels\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2488\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2489\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\env_slevels\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   4113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4114\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4115\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4116\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\env_slevels\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3078\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'instance_name'"
     ]
    }
   ],
   "source": [
    "b = df_no_hiring[df_no_hiring['instance_name']=='WEEKDENY']\n",
    "\n",
    "key_cs = 'customer_segmentation' # (A, AA, BB, etc.)\n",
    "key_reb = 'rebalance'\n",
    "\n",
    "b = b[[\n",
    "    'rebalance',\n",
    "    'customer_segmentation',\n",
    "    'mean_active',\n",
    "    'occupancy',\n",
    "    'distance_cruising',\n",
    "    'distance_loaded',\n",
    "    'distance_rebalancing',\n",
    "    'distance_total'\n",
    "]+[\"{}_{}\".format(service_level, sq_class) for sq_class in ['A', 'B', 'C'] for service_level in [\"MET\", \"UNMET\"]]+ ['MET_TOTAL', 'UNMET_TOTAL']]\n",
    "\n",
    "# Filtering data\n",
    "b = b[b[key_cs].isin([\"AA\", \"BB\", \"CC\"])]\n",
    "\n",
    "# convert just columns \"a\" and \"b\"\n",
    "#a[['contract_duration', 'median_seats', 'distance_total']] = a[['contract_duration', 'median_seats', 'distance_total']].apply(pd.to_numeric)\n",
    "\n",
    "b = b.astype({'distance_total':int})\n",
    "# Establishing category order and alias dictionaries\n",
    "dict_segmentation = {\"AA\":\"B+\", \"BB\":\"S+\", \"CC\":\"L+\", \"A\":\"B\", \"B\":\"S\", \"C\":\"L\"}\n",
    "category_segmentation = pd.api.types.CategoricalDtype(categories=[\"B+\", \"S+\", \"L+\", \"B\", \"S\", \"L\"], ordered=True)\n",
    "\n",
    "dict_service_rate = {\"S1\":\"SR1\", \"S2\":\"SR2\", \"S3\":\"SR3\"}\n",
    "category_service_rate = pd.api.types.CategoricalDtype(categories=[\"SR1\", \"SR2\", \"SR3\"], ordered=True)\n",
    "\n",
    "\n",
    "# Renaming data and applying aliases\n",
    "b[key_cs] = b[key_cs].map(lambda e:dict_segmentation[e])\n",
    "b[key_cs] = b[key_cs].astype(category_segmentation)\n",
    "\n",
    "b[key_reb] = b[key_reb].map(lambda e:( \"YES\" if e == True else \"NO\"))\n",
    "\n",
    "b = b.sort_values(by=[key_reb, key_cs])\n",
    "\n",
    "b.rename(columns={'customer_segmentation': 'Customer segmentation',\n",
    "                    'rebalance': 'Rebalance',\n",
    "                    'mean_active': '#Active vehicles/Round',\n",
    "                    'occupancy': 'Occupancy/Round',\n",
    "                    'distance_cruising': 'Cruising',\n",
    "                    'distance_rebalancing': 'Rebalancing',\n",
    "                    'distance_loaded': 'Servicing',\n",
    "                    'distance_total': 'Total (Km)'}, inplace=True)\n",
    "\n",
    "b = b.set_index([ 'Rebalance' , 'Customer segmentation'])\n",
    "\n",
    "b['#Active vehicles/Round'] = b['#Active vehicles/Round'].apply(lambda x:\"{:.2f}\".format(x))\n",
    "\n",
    "b = b[['#Active vehicles/Round', 'Occupancy/Round', 'MET_A', 'MET_B', 'MET_C', 'MET_TOTAL', 'UNMET_A', 'UNMET_B', 'UNMET_C', 'UNMET_TOTAL',  'Cruising', 'Servicing', 'Rebalancing', 'Total (Km)'] ]\n",
    "b[\"Service rate\"] = (b['MET_TOTAL']/(b['MET_TOTAL'] + b['UNMET_TOTAL'])).apply(lambda x: \"{:.2%}\".format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Service info (Rebalancing X No Rebalancing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_service = b[[\"Service rate\", 'MET_A', 'MET_B', 'MET_C', 'MET_TOTAL', 'UNMET_A', 'UNMET_B', 'UNMET_C', 'UNMET_TOTAL']]\n",
    "\n",
    "df_service = b[[\"Service rate\", 'MET_A', 'MET_B', 'MET_C', 'UNMET_A', 'UNMET_B', 'UNMET_C', 'UNMET_TOTAL']]\n",
    "\n",
    "\n",
    "df_service['MET_A'] =df_service['MET_A'].apply(lambda e: ('{:02}:{:02}'.format(int(e)//60, int(e)%60) if e != 0 else '-'))\n",
    "df_service['MET_B'] = df_service['MET_B'].apply(lambda e: ('{:02}:{:02}'.format(int(e)//60, int(e)%60) if e != 0 else '-'))\n",
    "df_service['MET_C'] = df_service['MET_C'].apply(lambda e: ('{:02}:{:02}'.format(int(e)//60, int(e)%60) if e != 0 else '-'))\n",
    "\n",
    "\n",
    "\n",
    "print(df_service.to_latex(multicolumn=True, multirow=True, column_format='ccccccllll'))\n",
    "df_service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fleet operation info (Rebalancing X No Rebalancing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fleet = b[['Occupancy/Round', '#Active vehicles/Round', 'Cruising', 'Servicing', 'Rebalancing', 'Total (Km)']]\n",
    "df_fleet['#Active vehicles/Round'] = (df_fleet['#Active vehicles/Round'].astype(float)/1000).apply(lambda x: \"{:.2%}\".format(x))\n",
    "print(df_fleet.to_latex(multicolumn=True, multirow=True, column_format='ccccccc'))\n",
    "df_fleet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hiring aggregate data - Fleet stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing all instances in folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all instances in folder\n",
    "instance_file_names = os.listdir(request_log_folder)\n",
    "\n",
    "\n",
    "# Instance Info (key = instance name)\n",
    "\n",
    "print(\"Reading files in folder:\", request_log_folder)\n",
    "dic_all_round_track = dict()\n",
    "\n",
    "for file_name in instance_file_names:\n",
    "    \n",
    "    instance, extension = file_name.split(\".\")\n",
    "        \n",
    "    # Instance settings\n",
    "    instance_settings_dic = get_instance_settings(instance)\n",
    "    \n",
    "    if instance_settings_dic['instance_name'] == \"HIRINGWEEKMAXWAITINGREB2\" or 'rebalance' not in instance_settings_dic.keys():\n",
    "        continue\n",
    "    if instance_settings_dic['customer_segmentation'] in ['A', 'B', 'C']:\n",
    "        continue\n",
    "  \n",
    "    #if instance_settings_dic['instance_name'] != 'HIRINGWEEKMAXWAITING':\n",
    "    #    continue\n",
    "        \n",
    "    print(\"  - Processing\", instance)\n",
    "    \n",
    "    round_track_agg_dic = get_results_dic(instances_folder, instance)\n",
    "    \n",
    "    # Get aggregated results\n",
    "    dic_all_round_track[instance] = {**instance_settings_dic, **round_track_agg_dic}\n",
    "\n",
    "#print(\"Instance settings:\")\n",
    "#pprint(dic_instance_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(dic_all_round_track, orient='index')\n",
    "df.to_csv(\"data1.csv\")\n",
    "\n",
    "# Getting latex table\n",
    "# print(a.to_latex(multicolumn=True, multirow=True))\n",
    "\n",
    "df\n",
    "\n",
    "df=df.fillna(-1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = df#[df['instance_name']=='HIRINGWEEKMAXWAITING']\n",
    "\n",
    "a = a[[\n",
    "    'service_rate',\n",
    "    'customer_segmentation',\n",
    "    'contract_duration',\n",
    "    'occupancy',\n",
    "    'o1',\n",
    "    'o2',\n",
    "    'o3',\n",
    "    'o4',\n",
    "    'v1',\n",
    "    'v2',\n",
    "    'v3',\n",
    "    'v4',\n",
    "    'avg_seats',\n",
    "    'id_max_seats',\n",
    "    'max_seats',\n",
    "    'median_seats',\n",
    "    'distance_cruising',\n",
    "    'distance_loaded',\n",
    "    'distance_rebalancing',\n",
    "    'distance_total',\n",
    "    \"serviced_seats\",\n",
    "    \"picking_up_seats\",\n",
    "    \"rebalancing_seats\",\n",
    "    \"parked_seats\",\n",
    "    \"avg_runtime\"\n",
    "    \n",
    "]]\n",
    "\n",
    "key_sr = 'service_rate' # (S1, S2, S3)\n",
    "key_cs = 'customer_segmentation' # (A, AA, BB, etc.)\n",
    "key_cd = 'contract_duration' #(0, 3600, 18000)\n",
    "\n",
    "\n",
    "# Filtering data\n",
    "a = a[a[key_cs].isin([\"AA\", \"BB\", \"CC\"])]\n",
    "\n",
    "# convert just columns \"a\" and \"b\"\n",
    "#a[['contract_duration', 'median_seats', 'distance_total']] = a[['contract_duration', 'median_seats', 'distance_total']].apply(pd.to_numeric)\n",
    "\n",
    "a = a.astype({'contract_duration':int, 'median_seats':int, 'distance_total':int, 'max_seats': int})\n",
    "# Establishing category order and alias dictionaries\n",
    "dict_segmentation = {\"AA\":\"B+\", \"BB\":\"S+\", \"CC\":\"L+\", \"A\":\"B\", \"B\":\"S\", \"C\":\"L\"}\n",
    "category_segmentation = pd.api.types.CategoricalDtype(categories=[\"B+\", \"S+\", \"L+\", \"B\", \"S\", \"L\"], ordered=True)\n",
    "\n",
    "dict_contract_duration = {3600:\"1h\", 0:\"Single-ride\", 10800:\"3h\", -1:\"Baseline\"}\n",
    "category_contract_duration = pd.api.types.CategoricalDtype(categories=[\"Single-ride\", \"1h\", \"3h\", \"Baseline\"], ordered=True)\n",
    "\n",
    "dict_service_rate = {\"S1\":\"SR1\", \"S2\":\"SR2\", \"S3\":\"SR3\", -1:\"Baseline\"}\n",
    "category_service_rate = pd.api.types.CategoricalDtype(categories=[\"SR1\", \"SR2\", \"SR3\",\"Baseline\"], ordered=True)\n",
    "\n",
    "\n",
    "# Renaming data and applying aliases\n",
    "a[key_cs] = a[key_cs].map(lambda e:dict_segmentation[e])\n",
    "a[key_cs] = a[key_cs].astype(category_segmentation)\n",
    "\n",
    "a[key_cd] = a[key_cd].map(lambda e:dict_contract_duration[e])\n",
    "a[key_cd] = a[key_cd].astype(category_contract_duration)\n",
    "\n",
    "a[key_sr] = a[key_sr].map(lambda e:dict_service_rate[e])\n",
    "a[key_sr] = a[key_sr].astype(category_service_rate)\n",
    "\n",
    "\n",
    "#a = a.sort_values(by=[key_sr, key_cs, key_cd])\n",
    "#a = a.sort_values(by=[key_cd, key_cs, key_sr])\n",
    "a = a.sort_values(by=[key_cs, key_cd, key_sr])\n",
    "\n",
    "\n",
    "\n",
    "a.rename(columns={'service_rate': 'Service rate',\n",
    "                    'customer_segmentation': 'Segmentation scenario',\n",
    "                    'contract_duration': 'Contract duration',\n",
    "                    'avg_seats': 'Avg',\n",
    "                    'max_seats': 'Max',\n",
    "                    'median_seats': 'Median',\n",
    "                    'distance_cruising': 'Cruising',\n",
    "                    'distance_rebalancing': 'Rebalancing',\n",
    "                    'distance_loaded': 'Servicing',\n",
    "                    'distance_total': 'Total (Km)'}, inplace=True)\n",
    "\n",
    "#a = a.set_index(['Service rate', 'Segmentation scenario', 'Contract duration'])\n",
    "#a = a.set_index(['Contract duration', 'Segmentation scenario', 'Service rate'])\n",
    "\n",
    "\n",
    "a.to_csv(\"fleet_stats.csv\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict()\n",
    "d['B+'] = 4544799\n",
    "d['S+'] = 4580364\n",
    "d['L+'] = 4560277\n",
    "\n",
    "a['dif'] = a['Total (Km)']\n",
    "for k,v in d.items():\n",
    "    a.loc[a[\"Segmentation scenario\"]==k, \"dif\"] = a.loc[a[\"Segmentation scenario\"]==k,\"dif\"].apply(lambda x:x-v)\n",
    "\n",
    "a = a.set_index(['Segmentation scenario', 'Contract duration', 'Service rate'])\n",
    "a.to_csv(\"fleet_stats.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.to_latex(multicolumn=True, multirow=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_hiring = pd.DataFrame.from_dict(dic_all, orient='index')\n",
    "df_no_hiring.to_csv(\"data1.csv\")\n",
    "\n",
    "df_no_hiring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b.to_latex(multicolumn=True, multirow=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building indexes for multilevel table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "dict_sl_status = {\"MET\":\"Met\", \"UNMET\":\"Unmet\"}\n",
    "filter_sl_status = [\"MET\"]\n",
    "instance_attribute = defaultdict(list)\n",
    " \n",
    "# Multilevel service level\n",
    "for instance_name, dic_request_track in dic_all_request_track.items():\n",
    "    \n",
    "    instance_settings = get_instance_settings(instance_name)\n",
    "    if instance_settings.get('service_rate', '-') == '-':\n",
    "        continue\n",
    "    \n",
    "    column = ('', 'service_rate')\n",
    "    instance_attribute[column].append(instance_settings['service_rate'])\n",
    "    column = ('', 'contract_duration')\n",
    "    instance_attribute[column].append(int(instance_settings['contract_duration']))\n",
    "    column = ('', 'customer_segmentation')\n",
    "    instance_attribute[column].append(instance_settings['customer_segmentation'])\n",
    "    \n",
    "    for sq_class, sl_status_dic in dic_request_track[\"service_levels\"].items():\n",
    "        for sl_status, attribute_dic in sl_status_dic.items():\n",
    "            for attribute, value in attribute_dic.items():\n",
    "                \n",
    "                # Filter sl_status\n",
    "                if sl_status in filter_sl_status:\n",
    "                    continue\n",
    "                \n",
    "                column = (dict_sq_class[sq_class], attribute)\n",
    "                if(column[1]==\"Count\"):\n",
    "                    instance_attribute[column].append(value if not (math.isnan(value) or value==0) else \"-\")\n",
    "                else:\n",
    "                    instance_attribute[column].append((\"{:.1f}\".format(value/60) if not math.isnan(value) else \"-\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table: What is the service level (pickup delay) of the users lying outside SQ-class service rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame.from_dict(instance_attribute)\n",
    "\n",
    "# Establishing category order and alias dictionaries\n",
    "dict_segmentation = {\"AA\":\"B+\", \"BB\":\"S+\", \"CC\":\"L+\", \"A\":\"B\", \"B\":\"S\", \"C\":\"L\"}\n",
    "category_segmentation = pd.api.types.CategoricalDtype(categories=[\"B+\", \"S+\", \"L+\", \"B\", \"S\", \"L\"], ordered=True)\n",
    "\n",
    "dict_contract_duration = {3600:\"1h\", 0:\"Single-ride\", 10800:\"3h\"}\n",
    "category_contract_duration = pd.api.types.CategoricalDtype(categories=[\"Single-ride\", \"1h\", \"3h\"], ordered=True)\n",
    "\n",
    "dict_service_rate = {\"S1\":\"SR1\", \"S2\":\"SR2\", \"S3\":\"SR3\"}\n",
    "category_service_rate = pd.api.types.CategoricalDtype(categories=[\"SR1\", \"SR2\", \"SR3\"], ordered=True)\n",
    "\n",
    "key_sr = ('', 'service_rate') # (S1, S2, S3)\n",
    "key_cs = ('', 'customer_segmentation') # (A, AA, BB, etc.)\n",
    "key_cd = ('', 'contract_duration') #(0, 3600, 18000)\n",
    "\n",
    "# Filtering data\n",
    "a = a[a[key_cs].isin([\"AA\", \"BB\", \"CC\"])]\n",
    "\n",
    "# Renaming data and applying aliases\n",
    "a[key_cs] = a[key_cs].map(lambda e:dict_segmentation[e])\n",
    "a[key_cs] = a[key_cs].astype(category_segmentation)\n",
    "\n",
    "a[key_cd] = a[key_cd].map(lambda e:dict_contract_duration[e])\n",
    "a[key_cd] = a[key_cd].astype(category_contract_duration)\n",
    "\n",
    "a[key_sr] = a[key_sr].map(lambda e:dict_service_rate[e])\n",
    "a[key_sr] = a[key_sr].astype(category_service_rate)\n",
    "\n",
    "a = a.sort_values(by=[key_sr, key_cs, key_cd])\n",
    "a = a.set_index([key_sr, key_cs, key_cd])\n",
    "\n",
    "a.index.names = [\"Service rate\",\"Segmentation scenario\",\"Contract duration\"]\n",
    "\n",
    "a\n",
    "\n",
    "# Getting latex table\n",
    "# print(a.to_latex(multicolumn=True, multirow=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
