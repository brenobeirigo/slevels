{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rebalance instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Overall configurations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Root\n",
    "root_path = os.getcwd().replace(\"\\\\\",\"/\")\n",
    "\n",
    "# Instance settings\n",
    "# instance_settings_path = \"C:/Users/LocalAdmin/IdeaProjects/slevels/src/main/resources/simulation.rebalancing/instance_settings_test_rebalancing.json\"\n",
    "instance_settings_path = \"C:/Users/LocalAdmin/IdeaProjects/slevels/src/main/resources/week/profile_time.json\"\n",
    "# Data translation\n",
    "dict_sl_status = {\"MET\":\"Shortest\", \"UNMET\":\"Extended\"}\n",
    "dict_sq_class = {\"A\":\"Business\", \"B\":\"Standard\", \"C\":\"Low-cost\"}\n",
    "dict_service = {\"FLEET\":\"Company-owned\", \"FREELANCE\":\"Third-party\"}\n",
    "category_segmentation = pd.api.types.CategoricalDtype(categories=[\"Business\", \"Standard\", \"Low-cost\"], ordered=True)\n",
    "category_fleet = pd.api.types.CategoricalDtype(categories=[\"Company-owned\", \"Third-party\"], ordered=True)\n",
    "category_status = pd.api.types.CategoricalDtype(categories=[\"Shortest\", \"Extended\"], ordered=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Loading the instance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########### INSTANCE SETTINGS ##################################################\n",
      "{'distances_file': 'C:/Users/LocalAdmin/OneDrive/leap_forward/street_network_server/tenv/data/out/manhattan_nyc/distance/dist_matrix_m.csv',\n",
      " 'instance_description': 'Parallel vs. Sequential execution - update fleet '\n",
      "                         'status',\n",
      " 'instance_name': 'S3',\n",
      " 'instances_folder': 'C:/Users/LocalAdmin/IdeaProjects/slevels/instance_output/profile_time/',\n",
      " 'labels': {'BA': 'batch_duration',\n",
      "            'CD': 'contract_duration',\n",
      "            'CS': 'customer_segmentation',\n",
      "            'CT': 'clear_target_list_every_round',\n",
      "            'HE': 'heuristic_rebalancing',\n",
      "            'ID': 'instance_description',\n",
      "            'IF': 'initial_fleet',\n",
      "            'IN': 'instance_name',\n",
      "            'MC': 'max_capacity',\n",
      "            'MO': 'allow_many_to_one',\n",
      "            'MR': 'max_requests',\n",
      "            'OP': 'optimal_rebalancing',\n",
      "            'RE': 'rebalance',\n",
      "            'RT': 'reinsert_targets',\n",
      "            'SD': 'allow_service_deterioration',\n",
      "            'SR': 'service_rate',\n",
      "            'ST': 'simulation_time',\n",
      "            'UR': 'allow_urgent_relocation',\n",
      "            'VH': 'allow_vehicle_hiring'},\n",
      " 'matching_config': {'sort_waiting_users_by_class': [False]},\n",
      " 'rebalancing_config': {'allow_many_to_one': [False, True],\n",
      "                        'allow_urgent_relocation': [True, False],\n",
      "                        'clear_target_list_every_round': [True, False],\n",
      "                        'rebalancing_method': ['rebalance_heuristic',\n",
      "                                               'rebalance_optimal_alonso_mora'],\n",
      "                        'reinsert_targets': [True, False]},\n",
      " 'requests_file': 'C:/Users/LocalAdmin/OneDrive/leap_forward/street_network_server/tenv/data/out/manhattan_nyc/tripdata/ids/tripdata_ids_2011-02-01_000000_2011-02-07_235959.csv',\n",
      " 'result_folder': 'C:/Users/LocalAdmin/IdeaProjects/slevels/instance_output/profile_time/',\n",
      " 'scenario_config': {'allow_service_deterioration': [False],\n",
      "                     'allow_vehicle_creation': [False],\n",
      "                     'allow_vehicle_hiring': [False],\n",
      "                     'batch_duration': [30],\n",
      "                     'contract_duration': [0],\n",
      "                     'customer_segmentation': {'BB': {'A': 0.16,\n",
      "                                                      'B': 0.68,\n",
      "                                                      'C': 0.16}},\n",
      "                     'initial_fleet': [1000],\n",
      "                     'max_capacity': [4],\n",
      "                     'max_requests': [1000],\n",
      "                     'rebalance': [True],\n",
      "                     'service_level': {'A': {'pk_delay': 180,\n",
      "                                             'sharing_preference': 0,\n",
      "                                             'trip_delay': 180},\n",
      "                                       'B': {'pk_delay': 300,\n",
      "                                             'sharing_preference': 1,\n",
      "                                             'trip_delay': 600},\n",
      "                                       'C': {'pk_delay': 600,\n",
      "                                             'sharing_preference': 1,\n",
      "                                             'trip_delay': 900}},\n",
      "                     'service_rate': {'S1': {'A': 0.9, 'B': 0.8, 'C': 0.7}},\n",
      "                     'time_horizon': [86400]}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def load_json(path):\n",
    "    \"\"\"Read json file and return dictionary\"\"\"\n",
    "\n",
    "    # Add .json to the end of file if needed\n",
    "    if path.find(\".json\") < 0:\n",
    "        path = path + \".json\"\n",
    "\n",
    "    # Read JSON file\n",
    "    with open(path) as data_file:\n",
    "        data_loaded = json.load(data_file)\n",
    "\n",
    "    return data_loaded\n",
    "\n",
    "instances_dic = load_json(instance_settings_path)\n",
    "\n",
    "# Folder where results will be saved\n",
    "result_folder = instances_dic[\"result_folder\"]\n",
    "request_log_folder = result_folder + \"/request_track\"\n",
    "\n",
    "# Folder where instances are located\n",
    "instances_folder = instances_dic[\"instances_folder\"]\n",
    "\n",
    "# File name aggregated data\n",
    "instance_name = instances_dic[\"instance_name\"]\n",
    "\n",
    "\n",
    "print(\"########### INSTANCE SETTINGS ##################################################\")\n",
    "pprint(instances_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get settings from instance name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E.g.:\n",
    "\n",
    "* Input = `IN-instanceName_BA-30_TH-86400_MR-1000_IF-1000_MC-06_CD-3600-SR-S1_CS-AA_SD_VH_MO_RT_CT_UR`\n",
    "\n",
    "* Output = \n",
    "{allow_many_to_one: True,\n",
    "allow_service_deterioration: True,\n",
    "allow_urgent_relocation: True,\n",
    "allow_vehicle_hiring: True,\n",
    "batch_duration: 30,\n",
    "clear_target_list_every_round: True,\n",
    "contract_duration: 3600,\n",
    "customer_segmentation: AA,\n",
    "initial_fleet: 1000,\n",
    "max_capacity: 06,\n",
    "max_requests: 1000,\n",
    "reinsert_targets: True,\n",
    "time_horizon: 86400}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instance_settings(file_name):\n",
    "    \"\"\" Read file name and return instance settings.\n",
    "    E.g.:\n",
    "     Input = IN-instanceName_BA-30_TH-86400_MR-1000_IF-1000_MC-06_CD-3600-SR-S1_CS-AA_SD_VH_MO_RT_CT_UR\n",
    "     Output = {'allow_many_to_one': True,\n",
    "                'allow_service_deterioration': True,\n",
    "                'allow_urgent_relocation': True,\n",
    "                'allow_vehicle_hiring': True,\n",
    "                'batch_duration': '30',\n",
    "                'clear_target_list_every_round': True,\n",
    "                'contract_duration': '3600',\n",
    "                'customer_segmentation': 'AA',\n",
    "                'initial_fleet': '1000',\n",
    "                'max_capacity': '06',\n",
    "                'max_requests': '1000',\n",
    "                'reinsert_targets': True,\n",
    "                'time_horizon': '86400'}\n",
    "    \"\"\"\n",
    "    label_setting_dic = instances_dic[\"labels\"]\n",
    "    \n",
    "    # print(file_name)\n",
    "        \n",
    "    # E.g., ['BA-30', 'TH-86400', 'MR-1000', 'IF-1000', 'MC-06', 'CD-3600-SR-S1', 'CS-AA', 'SD', 'VH', 'MO', 'RT', 'CT', 'UR']\n",
    "    file_instances = file_name.split(\"_\")\n",
    "\n",
    "    instance_settings = dict()\n",
    "\n",
    "    for e in file_instances:\n",
    "        \n",
    "        if e in label_setting_dic.keys():\n",
    "            # E.g., e =  SD\n",
    "            k = label_setting_dic[e]\n",
    "            # E.g., k = allow_service_deterioration\n",
    "            instance_settings[k] = True\n",
    "            \n",
    "        else:\n",
    "            # E.g., lv = [\"BA\", \"30\"]\n",
    "            lv  = e.split('-')\n",
    "            # E.g., e2 = BA\n",
    "            e2 = lv[0]\n",
    "            # E.g., k = batch_duration\n",
    "            k2 = label_setting_dic[e2]\n",
    "            \n",
    "            if len(lv) > 1:\n",
    "                 # E.g., v = '30'\n",
    "                v = lv[1]\n",
    "                instance_settings[k2] = v\n",
    "            else:\n",
    "                # label is not in instance name = False\n",
    "                instance_settings[k] = False\n",
    "\n",
    "    return instance_settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate results (folder round_track)\n",
    "\n",
    "Instance fields in `round_track` folder. Every line is a snapshot of a simulation round of 30 seconds (first column is round `timestamp`):\n",
    "\n",
    "#### Request status per round\n",
    "* `waiting`\n",
    "* `finished`\n",
    "* `denied`\n",
    "* `n_requests`\n",
    "\n",
    "#### Freelance vehicles per round\n",
    "* `hired_vehicles`\n",
    "* `deactivated_vehicles`\n",
    "\n",
    "#### Vehicle status per round\n",
    "* `active_vehicles`\n",
    "* `enroute_count`\n",
    "* `parked_vehicles`\n",
    "* `origin_vehicles`\n",
    "* `simulation.rebalancing`\n",
    "* `stopped_rebalancing`\n",
    "* `idle`\n",
    "* `picking_up`\n",
    "* `O1,O2,O3,O4`\n",
    "* `V1,V2,V3,V4`\n",
    "* `distance_traveled_cruising`\n",
    "* `distance_traveled_loaded`\n",
    "* `distance_traveled_rebalancing`\n",
    "* `run_time`\n",
    "\n",
    "#### Vehicle status per round (seats)\n",
    "* `seat_count`\n",
    "* `picking_up_seats`\n",
    "* `rebalancing_seats`\n",
    "* `empty_seats`\n",
    "* `total_capacity`\n",
    "\n",
    "#### Service quality\n",
    "* `pk_delay`\n",
    "* `total_delay`\n",
    "* `A_pk,A_dp,A_count,A_unmet_slevels`\n",
    "* `B_pk,B_dp,B_count,B_unmet_slevels`\n",
    "* `C_pk,C_dp,C_count,C_unmet_slevels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_results_dic(path_experiment, name_experiment):\n",
    "    \n",
    "    # Load results\n",
    "    experiment_file = \"{}round_track/{}.csv\".format(path_experiment, name_experiment)\n",
    "    \n",
    "    # print(\"Processing experiment file '{}'\".format(experiment_file))\n",
    "   \n",
    "\n",
    "    df = pd.read_csv(experiment_file, index_col=\"timestamp\",  parse_dates = True)\n",
    "\n",
    "    # Number of requests\n",
    "    total_requests = df[\"n_requests\"].sum()\n",
    "    serviced = df[\"finished\"][-1]\n",
    "    denied = df[\"denied\"][-1]\n",
    "    \n",
    "    # Service quality\n",
    "    sq_classes = [\"A\", \"B\", \"C\"]\n",
    "    sq_settings = [\"pk\", \"dp\", \"count\", \"unmet_slevels\"]\n",
    "    # e.g., ['A_pk', 'A_dp', 'A_count', 'A_unmet_slevels', 'B_pk', 'B_dp', 'B_count', 'B_unmet_slevels', 'C_pk', 'C_dp', 'C_count', 'C_unmet_slevels']\n",
    "    sq_user_labels = [\"{}_{}\".format(sq_class, sq_setting) for sq_class in sq_classes for sq_setting in sq_settings]\n",
    "    sq_user_dic = {l:df[l][-1] for l in sq_user_labels}\n",
    "    \n",
    "    # Distance traveled\n",
    "    distance_cruising = df[\"distance_traveled_cruising\"][-1]\n",
    "    distance_loaded = df[\"distance_traveled_loaded\"][-1]\n",
    "    distance_rebalancing = df[\"distance_traveled_rebalancing\"][-1]\n",
    "    distance_total = distance_cruising + distance_loaded + distance_rebalancing\n",
    "\n",
    "    # Pickup\n",
    "    avg_pk_delay = df[\"pk_delay\"].mean()\n",
    "    avg_ride_delay = df[\"total_delay\"].mean()\n",
    "\n",
    "    # Separate occupancy labels (e.g., O1, O2, O3, etc.)\n",
    "    occupancy_labels = [col for col in list(df) if 'O' in col]\n",
    "    status_labels = [ \"idle\", \"picking_up\"] + occupancy_labels\n",
    "    \n",
    "    # Get fleet makeup\n",
    "    fleet_makeup_labels = [col for col in list(df) if 'V' in col]\n",
    "    fleet_makeup = {mk:df[mk][-1] for mk in fleet_makeup_labels}\n",
    "    total_seats = {\"seats_\" + k:int(k[1:]) * v for k,v in fleet_makeup.items()}\n",
    "    total_seats[\"total_seats\"] = sum(total_seats.values())\n",
    "    #max_hired = df[\"hired\"].max()\n",
    "\n",
    "    # Runtime\n",
    "    time_ride_matching_ms = df[\"time_ride_matching_ms\"].sum()\n",
    "    time_update_fleet_status_ms = df[\"time_update_fleet_status_ms\"].sum()\n",
    "    time_vehicle_rebalancing_ms = df[\"time_vehicle_rebalancing_ms\"].sum()\n",
    "    \n",
    "    # Dictionary of agreggate data\n",
    "    dic_agreggate_data = {\"serviced\": \"{:.2%}\".format(serviced/total_requests),\n",
    "                          \"denied\": \"{:.2%}\".format(denied/total_requests),\n",
    "                          #'max_hired': max_hired,\n",
    "                          \"total_requests\": total_requests,\n",
    "                          \"avg_pk_delay\": \"{:.2f}\".format(avg_pk_delay),\n",
    "                          \"avg_ride_delay\": \"{:.2f}\".format(avg_ride_delay),\n",
    "                          \"time_ride_matching_ms\": \"{:.2f}\".format(time_ride_matching_ms/1000/60),\n",
    "                          \"time_update_fleet_status_ms\": \"{:.2f}\".format(time_update_fleet_status_ms/1000/60),\n",
    "                          \"time_vehicle_rebalancing_ms\": \"{:.2f}\".format(time_vehicle_rebalancing_ms/1000/60),\n",
    "                          \"distance_cruising\": \"{:.2%}\".format(distance_cruising/distance_total),\n",
    "                          \"distance_loaded\": \"{:.2%}\".format(distance_loaded/distance_total),\n",
    "                          \"distance_rebalancing\": \"{:.2%}\".format(distance_rebalancing/distance_total),\n",
    "                          \"distance_total\": distance_total//1000}\n",
    "    \n",
    "    # All data\n",
    "    dic_ag = {**dic_agreggate_data, **fleet_makeup}\n",
    "    dic_ag = {**dic_ag, **total_seats}\n",
    "    dic_ag = {**dic_ag, **sq_user_dic}\n",
    "\n",
    "    return dic_ag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate results (folder request_track)\n",
    "\n",
    "* `earliest`\n",
    "* `id` = 1, 2, 3, ..., #USERS\n",
    "* `class` = A, B, C\n",
    "* `pk_delay`\n",
    "* `ride_delay`\n",
    "* `pk_time`\n",
    "* `dp_time`\n",
    "* `id_from` = Network id\n",
    "* `id_to` = Network id\n",
    "* `dist` = trip(id_from, id_to) in seconds\n",
    "* `service` = {FLEET, FREELANCE}\n",
    "* `service_level` = {MET, UNMET}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "def get_request_track_dic(path_experiment, name_experiment):\n",
    "    \n",
    "    # Load results\n",
    "    experiment_file = \"{}request_track/{}.csv\".format(path_experiment, name_experiment)\n",
    "    \n",
    "    # print(\"Processing experiment file '{}'\".format(experiment_file))\n",
    "    df = pd.read_csv(experiment_file, index_col=\"earliest\",  parse_dates = True)\n",
    "    \n",
    "    aggfunc = {\"pk_delay\" : ['mean', 'count', 'max']}\n",
    "    \n",
    "    dfp = df.pivot_table(index=\"class\", columns=\"service_level\", aggfunc=aggfunc, values=[\"pk_delay\"])\n",
    "\n",
    "    return dfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "def get_request_track_dic(path_experiment, name_experiment):\n",
    "    \n",
    "    # Load results\n",
    "    experiment_file = \"{}request_track/{}.csv\".format(path_experiment, name_experiment)\n",
    "    \n",
    "    # print(\"Processing experiment file '{}'\".format(experiment_file))\n",
    "    df = pd.read_csv(experiment_file, index_col=\"earliest\",  parse_dates = True)\n",
    "    \n",
    "    aggfunc = {\"pk_delay\" : ['mean', 'count', 'max']}\n",
    "    \n",
    "    # Also can be done with pivot table\n",
    "    df_pivot = df.pivot_table(index=\"class\", columns=\"service_level\", aggfunc=aggfunc, values=[\"pk_delay\", \"id_from\"])\n",
    "\n",
    "\n",
    "    service_count = df['service'].value_counts().to_dict()\n",
    "    class_count = df['class'].value_counts().to_dict()\n",
    "    \n",
    "    # How many users had their service levels fulfilled (MET)? How many had their service levels deteriorated, or have been rejected (UNMET)?\n",
    "    service_level = df['service_level'].value_counts().to_dict()  \n",
    "    \n",
    "    # \n",
    "    service_quality_dic = {'A':{'MET': {'Avg.':None, 'Max.':None, 'Count':None}, 'UNMET': {'Avg.':None, 'Max.':None, 'Count':None}},\n",
    "                           'B':{'MET': {'Avg.':None, 'Max.':None, 'Count':None}, 'UNMET': {'Avg.':None, 'Max.':None, 'Count':None}},\n",
    "                           'C':{'MET': {'Avg.':None, 'Max.':None, 'Count':None}, 'UNMET': {'Avg.':None, 'Max.':None, 'Count':None}}}\n",
    " \n",
    "    for sq_class in ['A', 'B', 'C']:\n",
    "        for service_level in [\"MET\", \"UNMET\"]:\n",
    "            filter_sq_sl = (df['class'] == sq_class) & (df['service_level'] == service_level)\n",
    "            service_quality_dic[sq_class][service_level]['Max.'] = df.loc[filter_sq_sl][\"pk_delay\"].max()\n",
    "            service_quality_dic[sq_class][service_level]['Avg.'] = df.loc[filter_sq_sl][\"pk_delay\"].mean()\n",
    "            service_quality_dic[sq_class][service_level]['Count'] = df.loc[filter_sq_sl][\"pk_delay\"].count()\n",
    "    \n",
    "    # How many vehicles (freelance or from initial fleet) serviced each user (considering class and service quality status, that is, MET or UNMET)\n",
    "    fleet_settings_dic = {sq_class:{service_level:df.loc[(df['class']==sq_class) & \n",
    "                                                         (df['service_level']==service_level)][\"service\"].value_counts().to_dict()\n",
    "                                                   \n",
    "                                    for service_level in  [\"MET\", \"UNMET\"]}\n",
    "                          for sq_class in ['A', 'B', 'C']}\n",
    "    \n",
    "    dic_request_track = {\"service_levels\":service_quality_dic,\n",
    "                          \"fleet_settings\":fleet_settings_dic}\n",
    "    \n",
    "    return dic_request_track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing single instance"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Processing instance\n",
    "\n",
    "file_name = \"IN-HIRING_BA-30_ST-600_MR-1000_IF-10_MC-4_CS-AA_CD-0_SR-S1_VH_SD_RE_CT_RT_UR\"\n",
    "\n",
    "# Get instance settings according to file name\n",
    "instance_settings = get_instance_settings(file_name)\n",
    "\n",
    "# Filtered instance settings\n",
    "instance_settings = {key:value for key,value in instance_settings.items() if key in [\"customer_segmentation\",  \"service_rate\", \"contract_duration\"]}\n",
    "print(\"\\n##### Instance settings ################################################\")\n",
    "pprint(instance_settings)\n",
    "\n",
    "# Round track data\n",
    "round_track_dic = get_results_dic(instances_folder, file_name)\n",
    "print(\"\\n##### Round track ######################################################\")\n",
    "pprint(round_track_dic)\n",
    "\n",
    "# Request track data\n",
    "request_track_dic = get_request_track_dic(instances_folder, file_name)\n",
    "print(\"\\n##### Request track ####################################################\")\n",
    "pprint(request_track_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_aggregate_request_dic(path_experiment, name_experiment):\n",
    "    \n",
    "    # Load results\n",
    "    experiment_file = \"{}request_track/{}.csv\".format(path_experiment, name_experiment)\n",
    "    \n",
    "   \n",
    "    df = pd.read_csv(experiment_file, index_col = \"earliest\",  parse_dates = True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing all instances in folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files in folder: C:/Users/LocalAdmin/IdeaProjects/slevels/instance_output/profile_time//request_track\n",
      "  - Processing IN-S3_BA-30_ST-86400_MR-1000_IF-1000_MC-4_CS-BB_RE_CT_HE\n",
      "  - Processing IN-S3_BA-30_ST-86400_MR-1000_IF-1000_MC-4_CS-BB_RE_CT_MO_HE\n",
      "  - Processing IN-S3_BA-30_ST-86400_MR-1000_IF-1000_MC-4_CS-BB_RE_CT_MO_OP\n",
      "  - Processing IN-S3_BA-30_ST-86400_MR-1000_IF-1000_MC-4_CS-BB_RE_CT_MO_RT_HE\n",
      "  - Processing IN-S3_BA-30_ST-86400_MR-1000_IF-1000_MC-4_CS-BB_RE_CT_MO_RT_OP\n",
      "  - Processing IN-S3_BA-30_ST-86400_MR-1000_IF-1000_MC-4_CS-BB_RE_CT_MO_RT_UR_HE\n",
      "  - Processing IN-S3_BA-30_ST-86400_MR-1000_IF-1000_MC-4_CS-BB_RE_CT_MO_RT_UR_OP\n",
      "  - Processing IN-S3_BA-30_ST-86400_MR-1000_IF-1000_MC-4_CS-BB_RE_CT_MO_UR_HE\n",
      "  - Processing IN-S3_BA-30_ST-86400_MR-1000_IF-1000_MC-4_CS-BB_RE_CT_MO_UR_OP\n",
      "  - Processing IN-S3_BA-30_ST-86400_MR-1000_IF-1000_MC-4_CS-BB_RE_CT_OP\n",
      "  - Processing IN-S3_BA-30_ST-86400_MR-1000_IF-1000_MC-4_CS-BB_RE_CT_RT_HE\n",
      "  - Processing IN-S3_BA-30_ST-86400_MR-1000_IF-1000_MC-4_CS-BB_RE_CT_RT_OP\n",
      "  - Processing IN-S3_BA-30_ST-86400_MR-1000_IF-1000_MC-4_CS-BB_RE_CT_RT_UR_HE\n",
      "  - Processing IN-S3_BA-30_ST-86400_MR-1000_IF-1000_MC-4_CS-BB_RE_CT_RT_UR_OP\n",
      "  - Processing IN-S3_BA-30_ST-86400_MR-1000_IF-1000_MC-4_CS-BB_RE_CT_UR_HE\n",
      "  - Processing IN-S3_BA-30_ST-86400_MR-1000_IF-1000_MC-4_CS-BB_RE_CT_UR_OP\n",
      "  - Processing IN-S3_BA-30_ST-86400_MR-1000_IF-1000_MC-4_CS-BB_RE_HE\n",
      "  - Processing IN-S3_BA-30_ST-86400_MR-1000_IF-1000_MC-4_CS-BB_RE_MO_HE\n",
      "  - Processing IN-S3_BA-30_ST-86400_MR-1000_IF-1000_MC-4_CS-BB_RE_MO_OP\n",
      "  - Processing IN-S3_BA-30_ST-86400_MR-1000_IF-1000_MC-4_CS-BB_RE_MO_RT_HE\n",
      "  - Processing IN-S3_BA-30_ST-86400_MR-1000_IF-1000_MC-4_CS-BB_RE_MO_RT_OP\n",
      "  - Processing IN-S3_BA-30_ST-86400_MR-1000_IF-1000_MC-4_CS-BB_RE_MO_RT_UR_HE\n",
      "  - Processing IN-S3_BA-30_ST-86400_MR-1000_IF-1000_MC-4_CS-BB_RE_MO_RT_UR_OP\n",
      "  - Processing IN-S3_BA-30_ST-86400_MR-1000_IF-1000_MC-4_CS-BB_RE_MO_UR_HE\n",
      "  - Processing IN-S3_BA-30_ST-86400_MR-1000_IF-1000_MC-4_CS-BB_RE_MO_UR_OP\n",
      "  - Processing IN-S3_BA-30_ST-86400_MR-1000_IF-1000_MC-4_CS-BB_RE_OP\n",
      "  - Processing IN-S3_BA-30_ST-86400_MR-1000_IF-1000_MC-4_CS-BB_RE_RT_HE\n",
      "  - Processing IN-S3_BA-30_ST-86400_MR-1000_IF-1000_MC-4_CS-BB_RE_RT_OP\n",
      "  - Processing IN-S3_BA-30_ST-86400_MR-1000_IF-1000_MC-4_CS-BB_RE_RT_UR_HE\n",
      "  - Processing IN-S3_BA-30_ST-86400_MR-1000_IF-1000_MC-4_CS-BB_RE_RT_UR_OP\n",
      "  - Processing IN-S3_BA-30_ST-86400_MR-1000_IF-1000_MC-4_CS-BB_RE_UR_HE\n",
      "  - Processing IN-S3_BA-30_ST-86400_MR-1000_IF-1000_MC-4_CS-BB_RE_UR_OP\n"
     ]
    }
   ],
   "source": [
    "# Get all instances in folder\n",
    "instance_file_names = os.listdir(request_log_folder)\n",
    "instance_file_names = [i for i in instance_file_names if instances_dic['instance_name'] in i]\n",
    "\n",
    "# Instance Info (key = instance name)\n",
    "dic_all_instance_settings = dict()\n",
    "dic_all_round_track = dict()\n",
    "dic_all_request_track = dict()\n",
    "\n",
    "print(\"Reading files in folder:\", request_log_folder)\n",
    "for file_name in instance_file_names:\n",
    "    try:\n",
    "        \n",
    "        instance, extension = file_name.split(\".\")\n",
    "        print(\"  - Processing\", instance)\n",
    "\n",
    "        # Instance settings\n",
    "        instance_settings_dic = get_instance_settings(instance)\n",
    "        round_track_agg_dic = get_results_dic(instances_folder, instance)\n",
    "        request_track_agg_dic = get_request_track_dic(instances_folder, instance)\n",
    "\n",
    "        # Get aggregated results\n",
    "        dic_all_round_track[instance] = round_track_agg_dic\n",
    "        dic_all_request_track[instance] = request_track_agg_dic\n",
    "        dic_all_instance_settings[instance] = instance_settings_dic\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "    \n",
    "\n",
    "#print(\"Instance settings:\")\n",
    "#pprint(dic_instance_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building indexes for multilevel table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "dict_sl_status = {\"MET\":\"Met\", \"UNMET\":\"Unmet\"}\n",
    "filter_sl_status = [\"MET\"]\n",
    "instance_attribute = defaultdict(list)\n",
    " \n",
    "# Multilevel service level\n",
    "for instance_name, dic_request_track in dic_all_request_track.items():\n",
    "    \n",
    "    instance_settings = get_instance_settings(instance_name)\n",
    "    if instance_settings.get('service_rate', '-') == '-':\n",
    "        continue\n",
    "    \n",
    "    column = ('', 'service_rate')\n",
    "    instance_attribute[column].append(instance_settings['service_rate'])\n",
    "    column = ('', 'contract_duration')\n",
    "    instance_attribute[column].append(int(instance_settings['contract_duration']))\n",
    "    column = ('', 'customer_segmentation')\n",
    "    instance_attribute[column].append(instance_settings['customer_segmentation'])\n",
    "    \n",
    "    for sq_class, sl_status_dic in dic_request_track[\"service_levels\"].items():\n",
    "        for sl_status, attribute_dic in sl_status_dic.items():\n",
    "            for attribute, value in attribute_dic.items():\n",
    "                \n",
    "                # Filter sl_status\n",
    "                if sl_status in filter_sl_status:\n",
    "                    continue\n",
    "                \n",
    "                column = (dict_sq_class[sq_class], attribute)\n",
    "                if(column[1]==\"Count\"):\n",
    "                    instance_attribute[column].append(value if not (math.isnan(value) or value==0) else \"-\")\n",
    "                else:\n",
    "                    instance_attribute[column].append((\"{:.1f}\".format(value/60) if not math.isnan(value) else \"-\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame.from_dict(dic_all_round_track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.T\n",
    "a.to_csv(\"rebal.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table: What is the service level (pickup delay) of the users lying outside SQ-class service rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('', 'customer_segmentation')",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m~\\anaconda3\\envs\\env_slevels\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   2645\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2646\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2647\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: ('', 'customer_segmentation')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-12-093af87edccc>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[1;31m# Filtering data\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 18\u001B[1;33m a = a[a[key_cs].isin([\"AA\",\n\u001B[0m\u001B[0;32m     19\u001B[0m                       \u001B[1;34m\"BB\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m                       \"CC\"])]\n",
      "\u001B[1;32m~\\anaconda3\\envs\\env_slevels\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   2798\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnlevels\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2799\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getitem_multilevel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2800\u001B[1;33m             \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2801\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mis_integer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2802\u001B[0m                 \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\env_slevels\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mget_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m   2646\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2647\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2648\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_loc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_maybe_cast_indexer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2649\u001B[0m         \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_indexer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmethod\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtolerance\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtolerance\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2650\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mindexer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mindexer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msize\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\index.pyx\u001B[0m in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001B[0m in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: ('', 'customer_segmentation')"
     ]
    }
   ],
   "source": [
    "a = pd.DataFrame.from_dict(instance_attribute)\n",
    "\n",
    "# Establishing category order and alias dictionaries\n",
    "dict_segmentation = {\"AA\":\"B+\", \"BB\":\"S+\", \"CC\":\"L+\", \"A\":\"B\", \"B\":\"S\", \"C\":\"L\"}\n",
    "category_segmentation = pd.api.types.CategoricalDtype(categories=[\"B+\", \"S+\", \"L+\", \"B\", \"S\", \"L\"], ordered=True)\n",
    "\n",
    "dict_contract_duration = {3600:\"1h\", 0:\"Single-ride\", 10800:\"3h\"}\n",
    "category_contract_duration = pd.api.types.CategoricalDtype(categories=[\"Single-ride\", \"1h\", \"3h\"], ordered=True)\n",
    "\n",
    "dict_service_rate = {\"S1\":\"SR1\", \"S2\":\"SR2\", \"S3\":\"SR3\"}\n",
    "category_service_rate = pd.api.types.CategoricalDtype(categories=[\"SR1\", \"SR2\", \"SR3\"], ordered=True)\n",
    "\n",
    "key_sr = ('', 'service_rate') # (S1, S2, S3)\n",
    "key_cs = ('', 'customer_segmentation') # (A, AA, BB, etc.)\n",
    "key_cd = ('', 'contract_duration') #(0, 3600, 18000)\n",
    "\n",
    "# Filtering data\n",
    "a = a[a[key_cs].isin([\"AA\",\n",
    "                      \"BB\",\n",
    "                      \"CC\"])]\n",
    "\n",
    "# Renaming data and applying aliases\n",
    "a[key_cs] = a[key_cs].map(lambda e:dict_segmentation[e])\n",
    "a[key_cs] = a[key_cs].astype(category_segmentation)\n",
    "\n",
    "a[key_cd] = a[key_cd].map(lambda e:dict_contract_duration[e])\n",
    "a[key_cd] = a[key_cd].astype(category_contract_duration)\n",
    "\n",
    "a[key_sr] = a[key_sr].map(lambda e:dict_service_rate[e])\n",
    "a[key_sr] = a[key_sr].astype(category_service_rate)\n",
    "\n",
    "a = a.sort_values(by=[key_sr, key_cs, key_cd])\n",
    "a = a.set_index([key_sr, key_cs, key_cd])\n",
    "\n",
    "a.index.names = [\"Service rate\",\n",
    "                 \"Segmentation scenario\",\n",
    "                 \"Contract duration\"]\n",
    "\n",
    "a\n",
    "\n",
    "# Getting latex table\n",
    "# print(a.to_latex(multicolumn=True, multirow=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python37664bitenvslevelsconda0fcbcdd2fdaa4d328ecf1cbcb199e13d",
   "language": "python",
   "display_name": "Python 3.7.6 64-bit ('env_slevels': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}